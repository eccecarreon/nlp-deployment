{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This project has a large file size*\n",
    "\n",
    "Follow these instructions to use LFS on GitHub\n",
    "- git lfs install\n",
    "- git lfs track 'data/yelp-reviews.csv'\n",
    "- git add .gitattributes\n",
    "- git add data/yelp-reviews.csv\n",
    "- git commit -m 'Track large file with Git LFS'\n",
    "- git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# nltk.download('punkt')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# nltk.download('stopwords')\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# nltk.download('wordnet')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\nltk\\__init__.py:146\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjsontags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# PACKAGES\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\nltk\\chunk\\__init__.py:155\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: Chunkers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2024 NLTK Project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mClasses and interfaces for identifying non-overlapping linguistic\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mgroups (such as base noun phrases) in unrestricted text.  This task is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m     pattern is valid.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkParserI\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnamed_entity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Maxent_NE_Chunker\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpChunkParser, RegexpParser\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\nltk\\chunk\\api.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkScore\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserI\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChunkParserI\u001b[39;00m(ParserI):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    A processing interface for identifying non-overlapping groups in\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    unrestricted text.  Typically, chunk parsers are used to find base\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    will always generate a parse.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\nltk\\parse\\__init__.py:100\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecursivedescent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     96\u001b[0m     RecursiveDescentParser,\n\u001b[0;32m     97\u001b[0m     SteppingRecursiveDescentParser,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshiftreduce\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShiftReduceParser, SteppingShiftReduceParser\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransitionparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransitionParser\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestGrammar, extract_test_sentences, load_parser\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviterbi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViterbiParser\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\nltk\\parse\\transitionparser.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_svmlight_file\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kddcup99\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_kddcup99\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lfw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_lfw_pairs, fetch_lfw_people\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_olivetti_faces\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_olivetti_faces\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_openml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rcv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_rcv1\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_olivetti_faces.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loadmat\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, check_random_state\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\scipy\\io\\__init__.py:110\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_harwell_boeing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hb_read, hb_write\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m arff, harwell_boeing, idl, mmio, netcdf, wavfile\n\u001b[0;32m    112\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n",
      "File \u001b[1;32mc:\\Users\\erwin\\Desktop\\nlp-deployment\\.venv\\Lib\\site-packages\\scipy\\io\\arff\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mModule to read ARFF files\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m=========================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_arffread\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _arffread\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1086\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1154\u001b[0m, in \u001b[0;36m_cache_bytecode\u001b[1;34m(self, source_path, bytecode_path, data)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1179\u001b[0m, in \u001b[0;36mset_data\u001b[1;34m(self, path, data, _mode)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:191\u001b[0m, in \u001b[0;36m_write_atomic\u001b[1;34m(path, data, mode)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "file_path = 'data/yelp-reviews.csv'\n",
    "df = load_data(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "def perform_eda(df):\n",
    "    missing_values = df.isna().sum()\n",
    "    \n",
    "    print(f'Number of missing values: {missing_values}')\n",
    "\n",
    "perform_eda(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "statistics = df.describe().T\n",
    "print('Summary Statistics')\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark mode\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['stars'].value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
    "\n",
    "plt.title('Distribution of Star Ratings for Sandbar', fontsize=16)\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean text data\n",
    "def clean_data(df, text_column):\n",
    "    \n",
    "    # Remove missing values\n",
    "    df = df.dropna(subset=[text_column, 'stars'])\n",
    "    \n",
    "    # Normalize text data\n",
    "    df[text_column] = df[text_column].str.lower()\n",
    "    \n",
    "    # Remove punctuation and special characters\n",
    "    df[text_column] = df[text_column].apply(lambda x: re.sub(r'[^A-Za-z\\s]', '', x))\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_data(df, text_column='text')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN/missing values in the text column\n",
    "missing_text = df['text'].isna().sum()\n",
    "print(f'Number of missing values in text column: {missing_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering** (Tokenization and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('punkt_tab') if not downloaded\n",
    "\n",
    "# Initialize the stopwords object\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text => tokens, remove stopwords and join tokens\n",
    "def preprocess_text_to_tokens(text):\n",
    "    \n",
    "    # Tokeinize text and filter stopwords\n",
    "    filtered_tokens = [\n",
    "        word for word in word_tokenize(text.lower()) if word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    # Join the tokens into a string\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Create a tokens column and apply preprocessing to the text column and store the results in a tokens column\n",
    "df['tokens'] = df['text'].apply(preprocess_text_to_tokens)\n",
    "\n",
    "# Check transformations\n",
    "df[['text', 'tokens']].head() # return only the text and tokens columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer and stopwords object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocess text => lemmas, remove stopwords and join lemmas\n",
    "def preprocess_text_to_lemmas(text):\n",
    "    \n",
    "    # Lemmatize text and filter stopwords\n",
    "    lemmas = [\n",
    "        lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stop_words\n",
    "    ]\n",
    "    \n",
    "    # Join the lemmas into a string\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "# Create a lemmas column and apply preprocessing to the text column and store the results in a lemmas column\n",
    "df['lemmas'] = df['text'].apply(preprocess_text_to_lemmas)\n",
    "\n",
    "# Check transformations\n",
    "df[['text', 'lemmas']].head() # return only the text and lemmas columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display transformed dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series Preprocessing**\n",
    "- Create a resampled dataset for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert review dates to datetime objects\n",
    "# def convert_to_datetime(df, date_column):\n",
    "#     df[date_column] = pd.to_datetime(df[date_column], errors='coerce') # Convert to datetime, handle errors\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Set the date as the index\n",
    "# def set_date_as_index(df, date_column):\n",
    "#     df.set_index(date_column, inplace=True)\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Resample the data by a specific time interval\n",
    "# def resample_data(df, interval='ME'): # 'M' stands for months, 'D' stands for daily, 'W' for weekly\n",
    "#     df_resampled = df.resample(interval).mean()\n",
    "    \n",
    "#     return df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert date into datetime object\n",
    "def convert_to_datetime(df, date_column):\n",
    "    df[date_column] = pd.to_datetime(df[date_column], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Convert date to datetime\n",
    "df = convert_to_datetime(df, date_column='date')\n",
    "\n",
    "# Set date as index\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Resample numeric data\n",
    "def resample_numeric_data(df, interval='M'):\n",
    "    # Select only numeric columns for resampling\n",
    "    numeric_df = df.select_dtypes(include='number')\n",
    "    df_resampled = numeric_df.resample(interval).mean()\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "# Resample numeric data only\n",
    "df_resampled = resample_numeric_data(df, interval='M')\n",
    "print(df_resampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "output_path = 'data/reviews_processed.csv'\n",
    "df_resampled.to_csv(output_path)\n",
    "print(f'Processed dataframed saved to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataframe\n",
    "df_resampled = pd.read_csv('data/reviews_processed.csv', keep_default_na=False)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_resampled.isna().sum()\n",
    "print(f'Number of missing values: {missing_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Time Series Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Annotating the hightest and lowest points\n",
    "max_value = df_resampled['stars'].max()\n",
    "min_value = df_resampled['stars'].min()\n",
    "max_date = df_resampled['stars'].idxmax()\n",
    "min_date = df_resampled['stars'].idxmin()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_resampled.index, df_resampled['stars'], color='skyblue')\n",
    "plt.title('Average Star Ratings Over Time', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Star Rating')\n",
    "\n",
    "plt.annotate(f'Max {max_value:.2f}',\n",
    "             xy=(max_date, max_value),\n",
    "             xytext=(max_date, max_value + 0.05),\n",
    "             arrowprops=dict(facecolor='green', shrink=0.05))\n",
    "\n",
    "plt.annotate(f'Min {min_value:.2f}',\n",
    "             xy=(min_date, min_value),\n",
    "             xytext=(min_date, min_value + - 0.05),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 3 month-moving average\n",
    "df_resampled['3-month-MA'] = df_resampled['stars'].rolling(window=3).mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df_resampled.index, df_resampled['stars'], label='Monthly Average', color='skyblue')\n",
    "plt.plot(df_resampled.index, df_resampled['3-month-MA'], label='3-Month Moving Average', color='violet')\n",
    "plt.title('Average Star Ratings Over Time with 3 Month Moving Average', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Average Star Rating')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deep Learning**\n",
    "- Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Create sequences from the time series data\n",
    "# def create_sequences(data, sequence_length):\n",
    "    \n",
    "#     sequences = []\n",
    "#     targets = []\n",
    "    \n",
    "#     # Loop\n",
    "#     for start_index in range(len(data) - sequence_length):\n",
    "#         end_index = start_index + sequence_length\n",
    "#         sequence = data[start_index:end_index]\n",
    "#         target = data[end_index]\n",
    "        \n",
    "#         sequences.append(sequence)\n",
    "#         targets.append(target)\n",
    "    \n",
    "#     return np.array(sequences), np.array(targets)\n",
    "\n",
    "# # Sequence length 3 for quarterly, 6 is semi-annual, 12 is for annual\n",
    "# sequence_length = 3 # for 3 months or quarterly\n",
    "# X, y = create_sequences(df_resampled['stars'].values, sequence_length)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Model (Long Short Term Memory) Deep Learning Model\n",
    "\n",
    "common errors:\n",
    "- ModuleNotFoundError: No module named 'tensorflow'\n",
    "- `pip install tensorflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# def build_lstm_model(input_shape, units_first_layer, units_second_layer, dropout_first, dropout_second):\n",
    "    \n",
    "#     # Initialize model\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     # Add first layer with dropout\n",
    "#     model.add(LSTM(units=units_first_layer, return_sequences=True, input_shape=input_shape))\n",
    "#     model.add(Dropout(dropout_first))\n",
    "    \n",
    "#     # Add second layer with dropout\n",
    "#     model.add(LSTM(units=units_second_layer, return_sequences=False))\n",
    "#     model.add(Dropout(dropout_second))\n",
    "    \n",
    "#     # Add output layer\n",
    "#     model.add(Dense(units=1))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# # Compile the model\n",
    "# def compile_model(model, optimizer, loss):\n",
    "#     model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define input shape\n",
    "# input_shape = (X_train.shape[1], 1)\n",
    "\n",
    "# # Build the model\n",
    "# model = build_lstm_model(input_shape, units_first_layer=100, units_second_layer=50, dropout_first=0.5, dropout_second=0.2)\n",
    "\n",
    "# # Compile the model\n",
    "# model = compile_model(model, optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.keras import TqdmCallback\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(\n",
    "#     X_train,\n",
    "#     y_train,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[TqdmCallback(verbose=1)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "    \n",
    "#     test_loss = model.evaluate(X_test, y_test)\n",
    "#     print(f'Test Loss: {test_loss}')\n",
    "    \n",
    "#     return test_loss\n",
    "\n",
    "# def calculate_metrics(y_test, predictions):\n",
    "#     mse = mean_squared_error(y_test, predictions)\n",
    "#     mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "#     print(f'Mean Squared Error: {mse}')\n",
    "#     print(f'Mean Absolute Error: {mae}')\n",
    "    \n",
    "#     return mse, mae\n",
    "\n",
    "# def predict_and_evaluate(model, X_test, y_test):\n",
    "    \n",
    "#     # Evaluate model\n",
    "#     test_loss = evaluate_model(model, X_test, y_test)\n",
    "#     predictions = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     mse, mae = calculate_metrics(y_test, predictions)\n",
    "    \n",
    "#     return predictions, mse, mae\n",
    "\n",
    "# predictions, mse, mae = predict_and_evaluate(model, X_test, y_test)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test):\n",
    "#     test_loss = model.evaluate(X_test, y_test)\n",
    "#     print(f'Test Loss: {test_loss}')\n",
    "    \n",
    "#     return test_loss\n",
    "\n",
    "# def calculate_metrics(y_test, predictions):\n",
    "#     mse = mean_squared_error(y_test, predictions)\n",
    "#     mae = mean_absolute_error(y_test, predictions)\n",
    "    \n",
    "#     print(f'Mean Squared Error: {mse}')\n",
    "#     print(f'Mean Absolute Error: {mae}')\n",
    "    \n",
    "#     return mse, mae\n",
    "\n",
    "# def predict_and_evaluate(model, X_test, y_test):\n",
    "    \n",
    "#     # Evaluate model\n",
    "#     test_loss = evaluate_model(model, X_test, y_test)\n",
    "#     predictions = model.predict(X_test)\n",
    "    \n",
    "#     # Calculate metrics\n",
    "#     mse, mae = calculate_metrics(y_test, predictions)\n",
    "    \n",
    "#     return predictions, mse, mae\n",
    "\n",
    "# predictions, mse, mae = predict_and_evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_training_and_predictions(history, y_test, predictions):\n",
    "    \n",
    "#     fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "#     # Training and validation loss\n",
    "#     axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "#     axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "#     axes[0].set_title('Model Loss')\n",
    "#     axes[0].set_xlabel('Loss')\n",
    "#     axes[0].set_xlabel('Epoch')\n",
    "#     axes[0].legend()\n",
    "    \n",
    "#     # Prediction VS Actual Values\n",
    "#     axes[1].plot(y_test, label='Actual Values')\n",
    "#     axes[1].plot(predictions, label='Predicted Values')\n",
    "#     axes[1].set_title('Model Predictions VS Actual Values')\n",
    "#     axes[1].set_xlabel('Time')\n",
    "#     axes[1].set_xlabel('Star Rating')\n",
    "#     axes[1].legend()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "# print('LSTM Model Performance')\n",
    "# plot_training_and_predictions(history, y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model\n",
    "# model.save('models/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VADER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon') # if not already downloaded\n",
    "\n",
    "# Initialize the VADER object\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Apply VADER to the text data\n",
    "def apply_vader(text):\n",
    "    \n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "# Create vader_scores and vader_compound columns\n",
    "df['vader_scores'] = df['text'].apply(apply_vader)\n",
    "df['vader_compound'] = df['vader_scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# Convert compound score to sentiment labels\n",
    "def vader_sentiment_label(compound_score):\n",
    "    if compound_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "df['vader_sentiment'] = df['vader_compound'].apply(vader_sentiment_label)\n",
    "\n",
    "# Map stars to true_label for evaluation\n",
    "def map_stars_to_sentiment(stars):\n",
    "    if stars >= 4:\n",
    "        return 'Positive'\n",
    "    elif stars < 3:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "    \n",
    "df['true_label'] = df['stars'].apply(map_stars_to_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(df['true_label'], df['vader_sentiment'], labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "\n",
    "disp.plot(cmap='Purples')\n",
    "plt.title('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Vectorize text\n",
    "def vectorize_text(text_data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(text_data)\n",
    "    \n",
    "    return X, vectorizer\n",
    "\n",
    "# Create binary target based on star rating\n",
    "def prepare_target_variable(stars, threshold=4):\n",
    "    return stars >= threshold\n",
    "\n",
    "# Classifier model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    nb_classifier = MultinomialNB()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    return nb_classifier\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate_model_nb(model, X_test, y_test):\n",
    "    test_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    return accuracy, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Vectorize text\n",
    "X, vectorizer = vectorize_text(text_data=df['lemmas'])\n",
    "y = df['true_label']\n",
    "\n",
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Train model\n",
    "nb_classifier = train_naive_bayes(X_train, y_train)\n",
    "accuracy, test_pred = evaluate_model_nb(nb_classifier, X_test, y_test)\n",
    "\n",
    "print(f'Naive Bayes Accuracy with TF-IDF (Multi-Class): {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_test, test_pred, labels=labels)\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, test_pred, labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=labels)\n",
    "disp.plot(cmap='Purples')\n",
    "plt.title('Sentiment Analysis with Naive Bayes and TF-IDF (Multi-Class)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Calculate learning curves\n",
    "train_sizes, train_scores, test_scores = learning_curve(nb_classifier, X, y,\n",
    "                                                        cv=5,\n",
    "                                                        n_jobs=-1,\n",
    "                                                        train_sizes=np.linspace(0.1, 1.0, 10))\n",
    "\n",
    "# Plot the curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Training score', color='blue')\n",
    "plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Testing score', color='orange')\n",
    "plt.title('Naive Bayes Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Create a directory for models if it doesn't exist already\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save the model and vectorizer\n",
    "joblib.dump(nb_classifier, 'models/naive-bayes_model.pkl')\n",
    "joblib.dump(vectorizer, 'models/vectorizer.pkl')\n",
    "print('Model and vectorizer saved in the models directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and vectorizer\n",
    "loaded_nb_classifier = joblib.load('models/naive-bayes_model.pkl')\n",
    "loaded_vectorizer = joblib.load('models/vectorizer.pkl')\n",
    "print(f'Loaded Naive Bayes Model: {type(loaded_nb_classifier)} and vectorizer: {type(loaded_vectorizer)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sample input\n",
    "sample_text = ['This app is awesome BRO!']\n",
    "sample_vectorized = loaded_vectorizer.transform(sample_text) # transform the text into a matrix of token counts\n",
    "prediction = loaded_nb_classifier.predict(sample_vectorized)\n",
    "\n",
    "print(f'Predicted Statement: {prediction[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
